import gradio as gr
from openai import OpenAI
import os
import time
import html
import re
import base64
import mimetypes
from datetime import datetime
from typing import List, Tuple, Optional
from PIL import Image
import io

# å°è¯•åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… python-dotenvï¼Œç»§ç»­ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡
    pass

# --- é…ç½® ---
# å®‰å…¨çš„ API å¯†é’¥ç®¡ç†
API_KEY = os.environ.get("MODELSCOPE_API_KEY")
if not API_KEY:
    raise ValueError(
        "æœªæ‰¾åˆ° MODELSCOPE_API_KEY ç¯å¢ƒå˜é‡ã€‚\n"
        "è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼šexport MODELSCOPE_API_KEY=your_api_key_here\n"
        "æˆ–è€…åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼šMODELSCOPE_API_KEY=your_api_key_here"
    )

BASE_URL = "https://api-inference.modelscope.cn/v1/"
MODEL_ID = 'Qwen/Qwen3-235B-A22B-Instruct-2507'

# å®‰å…¨é…ç½® - æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
MAX_MESSAGE_LENGTH = int(os.environ.get("MAX_MESSAGE_LENGTH", 16000))  # é™åˆ¶å•æ¡æ¶ˆæ¯é•¿åº¦
MAX_HISTORY_LENGTH = int(os.environ.get("MAX_HISTORY_LENGTH", 50))     # é™åˆ¶å¯¹è¯å†å²é•¿åº¦
RATE_LIMIT_DELAY = int(os.environ.get("RATE_LIMIT_DELAY", 1))          # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB æ–‡ä»¶å¤§å°é™åˆ¶

# API é™åˆ¶é…ç½® - æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
MAX_OUTPUT_TOKENS = int(os.environ.get("MAX_OUTPUT_TOKENS", 32000))      # APIæœ€å¤§è¾“å‡ºtokenæ•° (32K)
DEFAULT_OUTPUT_TOKENS = int(os.environ.get("DEFAULT_OUTPUT_TOKENS", 8000))  # é»˜è®¤è¾“å‡ºtokenæ•° (8K)

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
SUPPORTED_TEXT_EXTENSIONS = {'.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv'}
SUPPORTED_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
try:
    client = OpenAI(
        base_url=BASE_URL,
        api_key=API_KEY,
    )
except Exception as e:
    print(f"Error initializing OpenAI client: {e}")
    client = None

# --- æ–‡ä»¶å¤„ç†å‡½æ•° ---

def process_uploaded_file(file_path: str) -> Tuple[str, str]:
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    
    Returns:
        Tuple[str, str]: (file_content, file_info)
    """
    if not file_path or not os.path.exists(file_path):
        return "", "æ–‡ä»¶ä¸å­˜åœ¨"
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(file_path)
    if file_size > MAX_FILE_SIZE:
        return "", f"æ–‡ä»¶è¿‡å¤§ ({file_size / 1024 / 1024:.1f}MB)ï¼Œæœ€å¤§æ”¯æŒ {MAX_FILE_SIZE / 1024 / 1024}MB"
    
    file_name = os.path.basename(file_path)
    file_ext = os.path.splitext(file_name)[1].lower()
    
    try:
        # å¤„ç†æ–‡æœ¬æ–‡ä»¶
        if file_ext in SUPPORTED_TEXT_EXTENSIONS:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            file_info = f"ğŸ“„ æ–‡ä»¶: {file_name} ({file_size} bytes)"
            return content, file_info
        
        # å¤„ç†å›¾ç‰‡æ–‡ä»¶
        elif file_ext in SUPPORTED_IMAGE_EXTENSIONS:
            # è¯»å–å¹¶å‹ç¼©å›¾ç‰‡
            with Image.open(file_path) as img:
                # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœéœ€è¦ï¼‰
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # è°ƒæ•´å¤§å°ï¼ˆä¿æŒæ¯”ä¾‹ï¼‰
                max_size = (800, 800)
                img.thumbnail(max_size, Image.Resampling.LANCZOS)
                
                # è½¬æ¢ä¸ºbase64
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            file_info = f"ğŸ–¼ï¸ å›¾ç‰‡: {file_name} ({img.size[0]}x{img.size[1]})"
            # è¿”å›base64ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼Œç”¨äºAPIè°ƒç”¨
            return f"data:image/jpeg;base64,{img_base64}", file_info
        
        else:
            return "", f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
    
    except Exception as e:
        return "", f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)[:100]}"

def get_timestamp() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return datetime.now().strftime("%H:%M:%S")

def format_message_with_timestamp(content: str, role: str) -> str:
    """ä¸ºæ¶ˆæ¯æ·»åŠ æ—¶é—´æˆ³"""
    timestamp = get_timestamp()
    if role == "user":
        return f"**[{timestamp}] æ‚¨:** {content}"
    else:
        return f"**[{timestamp}] AI:** {content}"

def export_conversation(history: List[dict]) -> str:
    """å¯¼å‡ºå¯¹è¯å†å²ä¸ºæ–‡æœ¬æ ¼å¼"""
    if not history:
        return "æš‚æ— å¯¹è¯è®°å½•"
    
    export_text = f"# å¯¹è¯è®°å½•å¯¼å‡º\nå¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    
    for msg in history:
        role = "ç”¨æˆ·" if msg["role"] == "user" else "AIåŠ©æ‰‹"
        content = msg["content"].replace("**[", "[").replace("] æ‚¨:**", "] æ‚¨:").replace("] AI:**", "] AI:")
        export_text += f"## {role}\n{content}\n\n"
    
    return export_text

def handle_export(history: List[dict]):
    """å¤„ç†å¯¹è¯å¯¼å‡º"""
    if not history:
        return None, show_notification("æš‚æ— å¯¹è¯è®°å½•å¯å¯¼å‡º", "warning")
    
    try:
        export_content = export_conversation(history)
        filename = f"conversation_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(export_content)
        
        return filename, show_notification(f"å¯¹è¯å·²æˆåŠŸå¯¼å‡ºåˆ° {filename}", "success")
    except Exception as e:
        return None, show_notification(f"å¯¼å‡ºå¤±è´¥: {str(e)[:50]}", "error")

def copy_last_response(history: List[dict]):
    """å¤åˆ¶æœ€åä¸€æ¡AIå›å¤"""
    if not history:
        return "âš ï¸ æš‚æ— å¯¹è¯è®°å½•"
    
    # æ‰¾åˆ°æœ€åä¸€æ¡AIå›å¤
    for msg in reversed(history):
        if msg["role"] == "assistant" and msg["content"].strip():
            # ç§»é™¤æ—¶é—´æˆ³æ ¼å¼
            content = msg["content"]
            if content.startswith("**[") and "] AI:**" in content:
                content = content.split("] AI:**", 1)[1].strip()
            
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥ä½¿ç”¨JavaScriptæ¥å¤åˆ¶åˆ°å‰ªè´´æ¿
            # ç°åœ¨åªæ˜¯æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
            return f"âœ… å·²å‡†å¤‡å¤åˆ¶: {content[:50]}{'...' if len(content) > 50 else ''}"
    
    return "âš ï¸ æœªæ‰¾åˆ°AIå›å¤"

def show_notification(message: str, msg_type: str = "info"):
    """æ˜¾ç¤ºé€šçŸ¥æ¶ˆæ¯"""
    icons = {"success": "âœ…", "error": "âŒ", "info": "â„¹ï¸", "warning": "âš ï¸"}
    icon = icons.get(msg_type, "â„¹ï¸")
    return f"{icon} {message}"

def get_api_info():
    """è·å–APIä¿¡æ¯å’Œé™åˆ¶"""
    return f"""
    ğŸ“Š **å½“å‰APIé…ç½®ä¿¡æ¯:**
    - æ¨¡å‹: {MODEL_ID}
    - æœ€å¤§è¾“å‡ºtokens: {MAX_OUTPUT_TOKENS}
    - é»˜è®¤è¾“å‡ºtokens: {DEFAULT_OUTPUT_TOKENS}
    - æœ€å¤§æ¶ˆæ¯é•¿åº¦: {MAX_MESSAGE_LENGTH} å­—ç¬¦
    - å¯¹è¯å†å²é™åˆ¶: {MAX_HISTORY_LENGTH} æ¡
    
    ğŸ’¡ **Tokenè¯´æ˜:**
    - 1 token â‰ˆ 0.75ä¸ªä¸­æ–‡å­—ç¬¦ æˆ– 1ä¸ªè‹±æ–‡å•è¯çš„ä¸€éƒ¨åˆ†
    - Qwenæ¨¡å‹é€šå¸¸æ”¯æŒ8K-32K+ tokensçš„ä¸Šä¸‹æ–‡é•¿åº¦
    - å½“å‰è®¾ç½®ä¸ºä¿å®ˆä¼°è®¡ï¼Œå¯æ ¹æ®å®é™…APIå“åº”è°ƒæ•´
    """

# --- å®‰å…¨å·¥å…·å‡½æ•° ---

def sanitize_input(text: str) -> str:
    """
    æ¸…ç†å’ŒéªŒè¯ç”¨æˆ·è¾“å…¥
    """
    if not text or not isinstance(text, str):
        return ""
    
    # ç§»é™¤æ½œåœ¨çš„æ¶æ„å­—ç¬¦
    text = html.escape(text.strip())
    
    # é™åˆ¶é•¿åº¦
    if len(text) > MAX_MESSAGE_LENGTH:
        text = text[:MAX_MESSAGE_LENGTH] + "..."
    
    return text

def validate_history(history: List[dict]) -> List[dict]:
    """
    éªŒè¯å’Œæ¸…ç†å¯¹è¯å†å²
    """
    if not history:
        return []
    
    # é™åˆ¶å†å²é•¿åº¦
    if len(history) > MAX_HISTORY_LENGTH:
        history = history[-MAX_HISTORY_LENGTH:]
    
    # æ¸…ç†æ¯æ¡æ¶ˆæ¯
    cleaned_history = []
    for item in history:
        if isinstance(item, dict) and "role" in item and "content" in item:
            clean_content = sanitize_input(item["content"])
            if clean_content or item["role"] == "assistant":  # ä¿ç•™æ‰€æœ‰åŠ©æ‰‹æ¶ˆæ¯å’Œæœ‰æ•ˆç”¨æˆ·æ¶ˆæ¯
                cleaned_history.append({"role": item["role"], "content": clean_content})
    
    return cleaned_history

# ç®€å•çš„é€Ÿç‡é™åˆ¶
last_request_time = 0

def rate_limit_check() -> bool:
    """
    æ£€æŸ¥é€Ÿç‡é™åˆ¶
    """
    global last_request_time
    current_time = time.time()
    
    if current_time - last_request_time < RATE_LIMIT_DELAY:
        return False
    
    last_request_time = current_time
    return True

# --- Gradio åº”ç”¨æ ¸å¿ƒé€»è¾‘ ---

def predict(message: str, history: List[dict], uploaded_file=None, temperature=0.7, max_tokens=DEFAULT_OUTPUT_TOKENS):
    """
    æ ¸å¿ƒé¢„æµ‹å‡½æ•°ï¼Œç”¨äºç”Ÿæˆ AI å›å¤ã€‚
    
    Args:
        message (str): ç”¨æˆ·è¾“å…¥çš„æœ€æ–°æ¶ˆæ¯ã€‚
        history (List[dict]): Gradio Chatbot æä¾›çš„å¯¹è¯å†å²ã€‚
                              æ ¼å¼ä¸º [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
    
    Yields:
        List[dict]: æ›´æ–°åçš„å¯¹è¯å†å²ï¼Œç”¨äºæµå¼æ›´æ–° Chatbot UIã€‚
    """
    # å®‰å…¨æ£€æŸ¥
    if not client:
        yield history + [{"role": "user", "content": message}, {"role": "assistant", "content": "é”™è¯¯ï¼šOpenAI å®¢æˆ·ç«¯æœªæˆåŠŸåˆå§‹åŒ–ã€‚è¯·æ£€æŸ¥ API å¯†é’¥å’Œç½‘ç»œè¿æ¥ã€‚"}]
        return
    
    # é€Ÿç‡é™åˆ¶æ£€æŸ¥
    if not rate_limit_check():
        yield history + [{"role": "user", "content": message}, {"role": "assistant", "content": "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚"}]
        return
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    file_content = ""
    file_info = ""
    if uploaded_file:
        file_content, file_info = process_uploaded_file(uploaded_file.name)
        if file_info and not file_content and "å¤±è´¥" in file_info:
            yield history + [{"role": "user", "content": message}, {"role": "assistant", "content": f"æ–‡ä»¶å¤„ç†é”™è¯¯: {file_info}"}]
            return
    
    # è¾“å…¥éªŒè¯å’Œæ¸…ç†
    clean_message = sanitize_input(message)
    if not clean_message and not file_content:
        yield history + [{"role": "user", "content": ""}, {"role": "assistant", "content": "è¯·è¾“å…¥æ¶ˆæ¯æˆ–ä¸Šä¼ æ–‡ä»¶ã€‚"}]
        return
    
    # å¦‚æœæœ‰æ–‡ä»¶å†…å®¹ï¼Œå°†å…¶æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
    is_image = file_content.startswith("data:image/") if file_content else False
    
    if file_content:
        if is_image:
            # å¯¹äºå›¾ç‰‡ï¼Œç›®å‰ModelScope APIå¯èƒ½ä¸æ”¯æŒè§†è§‰åŠŸèƒ½ï¼Œæ‰€ä»¥æä¾›æè¿°
            if clean_message:
                clean_message = f"{clean_message}\n\n[å·²ä¸Šä¼ å›¾ç‰‡: {file_info}]"
            else:
                clean_message = f"æˆ‘ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡: {file_info}ï¼Œè¯·å‘Šè¯‰æˆ‘å¦‚ä½•å¤„ç†å›¾ç‰‡æ–‡ä»¶ã€‚"
        else:
            # å¯¹äºæ–‡æœ¬æ–‡ä»¶ï¼Œç›´æ¥åŒ…å«å†…å®¹
            if clean_message:
                clean_message = f"{clean_message}\n\n[æ–‡ä»¶å†…å®¹]\n{file_content}"
            else:
                clean_message = f"è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶:\n\n{file_content}"
    
    clean_history = validate_history(history)
    
    # 1. å‡†å¤‡ API è¯·æ±‚æ‰€éœ€çš„æ¶ˆæ¯æ ¼å¼
    # ç³»ç»Ÿæç¤º - æ›´å®‰å…¨çš„ç³»ç»Ÿæç¤º
    api_messages = [{
        'role': 'system', 
        'content': 'You are a helpful, harmless, and honest assistant. Do not provide harmful, illegal, or inappropriate content.'
    }]
    
    # æ·»åŠ å†å²å¯¹è¯
    api_messages.extend(clean_history)
        
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    api_messages.append({'role': 'user', 'content': clean_message})

    # 2. è°ƒç”¨æ¨¡å‹ API å¹¶å¼€å¯æµå¼å“åº”
    try:
        stream = client.chat.completions.create(
            model=MODEL_ID,
            messages=api_messages,
            stream=True,
            max_tokens=max_tokens,  # ç”¨æˆ·å¯æ§åˆ¶çš„å“åº”é•¿åº¦
            temperature=temperature,  # ç”¨æˆ·å¯æ§åˆ¶çš„éšæœºæ€§
        )
    except Exception as e:
        error_msg = f"API è°ƒç”¨å¤±è´¥: {str(e)[:100]}..."  # é™åˆ¶é”™è¯¯æ¶ˆæ¯é•¿åº¦
        yield clean_history + [{"role": "user", "content": clean_message}, {"role": "assistant", "content": error_msg}]
        return

    # 3. å¤„ç†æµå¼å“åº”å¹¶æ›´æ–° UI
    # é¦–å…ˆï¼Œå°†ç”¨æˆ·çš„æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•ä¸­ï¼ŒAI çš„å›å¤æš‚æ—¶ä¸ºç©º
    user_msg_with_timestamp = format_message_with_timestamp(clean_message, "user")
    clean_history.extend([
        {"role": "user", "content": user_msg_with_timestamp},
        {"role": "assistant", "content": ""}
    ])
    
    # é€å—æ¥æ”¶å’Œå¤„ç†æµå¼æ•°æ®
    bot_response = ""
    try:
        for chunk in stream:
            if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
                content = chunk.choices[0].delta.content
                if content is not None:
                    bot_response += content
                    # é™åˆ¶å“åº”é•¿åº¦
                    if len(bot_response) > MAX_MESSAGE_LENGTH:
                        bot_response = bot_response[:MAX_MESSAGE_LENGTH] + "..."
                        break
                    
                    # æ›´æ–°å†å²è®°å½•ä¸­æœ€åä¸€æ¡ï¼ˆä¹Ÿå°±æ˜¯å½“å‰ AIï¼‰çš„å›å¤
                    ai_msg_with_timestamp = format_message_with_timestamp(bot_response, "assistant")
                    clean_history[-1]["content"] = ai_msg_with_timestamp
                    # é€šè¿‡ yield æ›´æ–° Gradio Chatbot UI
                    yield clean_history
    except Exception as e:
        error_msg = f"æµå¼å“åº”å¤„ç†å¤±è´¥: {str(e)[:100]}..."
        error_msg_with_timestamp = format_message_with_timestamp(error_msg, "assistant")
        clean_history[-1]["content"] = error_msg_with_timestamp
        yield clean_history

# --- Gradio UI ç•Œé¢æ„å»º ---

# è‡ªå®šä¹‰CSSæ ·å¼
custom_css = """
#chatbot { 
    min-height: 600px;
    border-radius: 10px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}
.message-timestamp {
    font-size: 0.8em;
    color: #666;
    margin-bottom: 5px;
}
.export-button {
    background: linear-gradient(45deg, #4CAF50, #45a049);
    color: white;
    border: none;
    border-radius: 5px;
    padding: 10px 20px;
    cursor: pointer;
    transition: all 0.3s ease;
}
.export-button:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.2);
}
.parameter-panel {
    background: #f5f5f5;
    padding: 15px;
    border-radius: 10px;
    margin: 10px 0;
    border: 1px solid #e0e0e0;
}
.file-upload {
    border: 2px dashed #4CAF50;
    border-radius: 10px;
    padding: 20px;
    text-align: center;
    transition: all 0.3s ease;
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
}
.file-upload:hover {
    border-color: #45a049;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
}
.status-message {
    padding: 10px;
    border-radius: 5px;
    margin: 5px 0;
    font-weight: bold;
}
.success {
    background-color: #d4edda;
    color: #155724;
    border: 1px solid #c3e6cb;
}
.error {
    background-color: #f8d7da;
    color: #721c24;
    border: 1px solid #f5c6cb;
}
"""

with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown(
        """
        # ğŸ¤– Qwen3 å¤§æ¨¡å‹å¯¹è¯åº”ç”¨
        
        è¿™æ˜¯ä¸€ä¸ªåŸºäº Gradio å’Œ ModelScope Qwen3 æ¨¡å‹ API æ„å»ºçš„ AI èŠå¤©æœºå™¨äººã€‚
        
        - **æŒç»­å¯¹è¯**: åº”ç”¨ä¼šè®°å½•æ‚¨çš„å¯¹è¯å†å²ï¼ŒAI çš„å›ç­”ä¼šåŸºäºä¸Šä¸‹æ–‡ã€‚
        - **æµå¼è¾“å‡º**: AI çš„å›ç­”ä¼šåƒæ‰“å­—ä¸€æ ·é€å­—æ˜¾ç¤ºï¼Œæå‡äº¤äº’ä½“éªŒã€‚
        - **ä¸€é”®æ¸…ç©º**: ç‚¹å‡»â€œæ¸…é™¤â€æŒ‰é’®å¯ä»¥éšæ—¶å¼€å§‹æ–°çš„å¯¹è¯ã€‚
        """
    )
    
    chatbot = gr.Chatbot(
        label="å¯¹è¯çª—å£",
        type="messages",
        elem_id="chatbot"
    )
    
    # å‚æ•°æ§åˆ¶é¢æ¿
    with gr.Accordion("ğŸ›ï¸ AI å‚æ•°è®¾ç½®", open=False):
        with gr.Row():
            temperature_slider = gr.Slider(
                minimum=0.1,
                maximum=2.0,
                value=0.7,
                step=0.1,
                label="åˆ›é€ æ€§ (Temperature)",
                info="æ•°å€¼è¶Šé«˜ï¼Œå›ç­”è¶Šæœ‰åˆ›æ„ä½†å¯èƒ½ä¸å¤Ÿå‡†ç¡®"
            )
            max_tokens_slider = gr.Slider(
                minimum=100,
                maximum=MAX_OUTPUT_TOKENS,
                value=DEFAULT_OUTPUT_TOKENS,
                step=100,
                label="æœ€å¤§å›å¤é•¿åº¦ (Max Tokens)",
                info=f"é™åˆ¶AIå›å¤çš„æœ€å¤§tokenæ•° (1 token â‰ˆ 0.75ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œæœ€å¤§{MAX_OUTPUT_TOKENS})"
            )
        
        # APIä¿¡æ¯æ˜¾ç¤º
        with gr.Accordion("ğŸ“Š APIä¿¡æ¯", open=False):
            gr.Markdown(get_api_info())
    
    with gr.Row():
        msg_textbox = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œç„¶åæŒ‰ Enter é”®æˆ–ç‚¹å‡»â€œå‘é€â€æŒ‰é’®",
            container=False,
        )
        submit_btn = gr.Button("å‘é€", variant="primary", scale=1, min_width=0)

    with gr.Row():
        file_upload = gr.File(
            label="ğŸ“ æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»ä¸Šä¼  (æ”¯æŒæ–‡æœ¬æ–‡ä»¶å’Œå›¾ç‰‡)",
            file_types=[".txt", ".md", ".py", ".js", ".html", ".css", ".json", ".xml", ".csv", 
                       ".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp"],
            file_count="single"
        )
    
    # åŠŸèƒ½æŒ‰é’®åŒºåŸŸ
    with gr.Row():
        export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºå¯¹è¯", variant="secondary", scale=1)
        copy_btn = gr.Button("ğŸ“‹ å¤åˆ¶æœ€åå›å¤", variant="secondary", scale=1)
        clear_btn = gr.ClearButton(
            [msg_textbox, chatbot, file_upload], 
            value="ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", 
            variant="stop",
            scale=1
        )
    
    # å¯¼å‡ºæ–‡ä»¶ä¸‹è½½ç»„ä»¶å’ŒçŠ¶æ€æ˜¾ç¤º
    export_file = gr.File(label="ğŸ“¥ å¯¼å‡ºçš„å¯¹è¯æ–‡ä»¶", visible=False)
    status_display = gr.Textbox(
        label="ğŸ“¢ æ“ä½œçŠ¶æ€", 
        placeholder="æ“ä½œçŠ¶æ€å°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
        interactive=False,
        max_lines=2
    )



    # --- äº‹ä»¶ç»‘å®š ---
    
    # ç»‘å®šâ€œå‘é€â€æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶
    submit_btn.click(predict, [msg_textbox, chatbot, file_upload, temperature_slider, max_tokens_slider], chatbot)
    
    # ç»‘å®šæ–‡æœ¬æ¡†çš„å›è½¦äº‹ä»¶
    msg_textbox.submit(predict, [msg_textbox, chatbot, file_upload, temperature_slider, max_tokens_slider], chatbot)
    
    # ç»‘å®šå¯¼å‡ºæŒ‰é’®
    export_btn.click(
        handle_export,
        [chatbot],
        [export_file, status_display]
    )
    
    # ç»‘å®šå¤åˆ¶æŒ‰é’®
    copy_btn.click(
        copy_last_response,
        [chatbot],
        status_display
    )
    
    # ä¸»é¢˜åˆ‡æ¢åŠŸèƒ½ï¼ˆç®€å•å®ç°ï¼‰
    def toggle_theme():
        return "ğŸŒ æµ…è‰²ä¸»é¢˜" if "ğŸŒ“" in theme_btn.value else "ğŸŒ“ åˆ‡æ¢ä¸»é¢˜"
    
    # æ¸…ç©ºæ–‡æœ¬æ¡†ï¼Œä¸ºä¸‹ä¸€æ¬¡è¾“å…¥åšå‡†å¤‡
    submit_btn.click(lambda: "", None, msg_textbox)
    msg_textbox.submit(lambda: "", None, msg_textbox)


if __name__ == "__main__":
    # å¯åŠ¨ Gradio åº”ç”¨
    # share=True ä¼šåˆ›å»ºä¸€ä¸ªå…¬å¼€é“¾æ¥ï¼Œæ–¹ä¾¿åˆ†äº«
    demo.launch(share=True)
